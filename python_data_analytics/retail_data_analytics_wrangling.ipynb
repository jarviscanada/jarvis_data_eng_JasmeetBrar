{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Data Wrangling and Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from PSQL into DataFrame\n",
    "\n",
    "**Setup Docker Containers**\n",
    "\n",
    "![](https://i.imgur.com/VQrBVBk.jpg)\n",
    "\n",
    "```\n",
    "#make sure you have both Jupyter and PSQL docker container running\n",
    "docker ps\n",
    "\n",
    "#Attach a bridge network to both containers so they can communicate with each other\n",
    "docker network create jarvis-net\n",
    "#this command works on running containers\n",
    "docker network connect jarvis-net jarvis-jupyter\n",
    "docker network connect jarvis-net jarvis-psql\n",
    "\n",
    "#verify both containers are attached to the jarvis-net\n",
    "docker network inspect trading-net\n",
    "\n",
    "#Note: instead of using `localhost`, you should use container names as hostnames.\n",
    "```\n",
    "\n",
    "**Data Preperation**\n",
    "\n",
    "- Use [pandas.read_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html) api to load the PSQL retail table into a Pandas DataFrame\n",
    "\n",
    "![](https://i.imgur.com/AmkAP63.jpg)\n",
    "\n",
    "- Get familair with the transaction date with `df.head()`, `df.sample(10)`, `df.info()`, `df.describe()`, etc..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install psql \"driver\"\n",
    "!pip3 install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code in one or more cells (please remove this line from your notebook)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine_string = \"postgresql://postgres:password@localhost:5432/postgres\"\n",
    "engine = create_engine(engine_string)\n",
    "retail_df = pd.read_sql_table(\"retail\", engine)\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()\n",
    "retail_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV into Dataframe\n",
    "Alternatively, the LGS IT team also dumped the transactional data into a [CSV file](https://raw.githubusercontent.com/jarviscanada/jarvis_data_eng_demo/feature/data/python_data_wrangling/data/online_retail_II.csv). However, the CSV header (column names) doesn't follow the snakecase or camelcase naming convention (e.g. `Customer ID` instead of `customer_id` or `CustomerID`). As a result, you will need to use Pandas to clean up the data before doing any analytics. In addition, unlike the PSQL scheme, CSV files do not have data types associated. Therefore, you will need to cast/convert certain columns into correct data types (e.g. DateTime, numbers, etc..)\n",
    "\n",
    "**Data Preperation**\n",
    "\n",
    "- Read the `data/online_retail_II.csv` file into a DataFrame\n",
    "- Rename all columns to upper camelcase or snakecase\n",
    "- Convert/cast all columns to the appropriate data types (e.g. datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = pd.read_csv(\"data/online_retail_II.csv\")\n",
    "\n",
    "for i, val in enumerate(retail_df.columns.values):\n",
    "    retail_df.columns.values[i] = val.replace(\" \", \"\")\n",
    "\n",
    "retail_df[\"Quantity\"] = pd.to_numeric(retail_df[\"Quantity\"])\n",
    "retail_df[\"InvoiceDate\"] = pd.to_datetime(retail_df[\"InvoiceDate\"])\n",
    "retail_df[\"Price\"] = pd.to_numeric(retail_df[\"Price\"])\n",
    "retail_df[\"CustomerID\"] = pd.to_numeric(retail_df[\"CustomerID\"])\n",
    "\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Invoice Amount Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "1. Calculate the invoice amount. Note: an invoice consists of one or more items where each item is a row in the df. (hint: you need to `GROUP BY invoice`)\n",
    "2. Draw the distribution of invoice amount with min, max, median, mod, and mean. However, you will notice many outlier data (e.g. invoices with large amounts). Sample hist and box charts:\n",
    "\n",
    "![](https://i.imgur.com/N8hsbDa.jpg)\n",
    "\n",
    "3. Draw the distribution for the first 85 quantiles of the invoice amount data with min, max, median, mod, and mean.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/tJrH1qj.jpg)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code in one or more cells (please remove this line from your notebook)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_distribution(data):\n",
    "    minimum = data.min()\n",
    "    mean = data.mean()\n",
    "    median = data.median()\n",
    "    mode = data.mode()[0]\n",
    "    maximum = data.max()\n",
    "\n",
    "    print(\"Minimum: {:.2f}\\nMean: {:.2f}\\nMedian: {:.2f}\\nMode: {:.2f}\\nMaximum: {:.2f}\\n\".format(minimum, mean, median, mode, maximum))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(data)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Data Distribution\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.boxplot(data, vert=False)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df = retail_df.loc[(retail_df[\"Quantity\"] > 0) & (retail_df[\"Price\"] > 0), [\"Invoice\", \"Quantity\", \"Price\"]]\n",
    "invoice_amounts = invoice_df[\"Quantity\"] * invoice_df[\"Price\"]\n",
    "invoice_amounts_df = pd.concat([invoice_df[\"Invoice\"], invoice_amounts], axis=1)\n",
    "invoice_amounts_df.columns = [\"Invoice\", \"Amount\"]\n",
    "invoice_amounts_df = invoice_amounts_df.groupby([\"Invoice\"]).sum()\n",
    "\n",
    "show_distribution(invoice_amounts_df[\"Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers = invoice_amounts_df[invoice_amounts_df.Amount <= invoice_amounts_df.Amount.quantile(0.85)]\n",
    "show_distribution(remove_outliers[\"Amount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Placed and Canceled Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "- The attribute information (see the `project kick-off` section) contains useful information that helps you to identify canceled orders\n",
    "- To simplify the problem, you can assume that there are two invoice numbers for each canceled order (one for the original invoice and one for the canceled invoice). Therefore, `# of placed orders = total # of orders - 2 * canceled order`. Furthermore, you can also assume the original invoice and canceled invoice are on always on the same day (this eliminate the case where the original invoice and canceled invoices are on different months)\n",
    "- hints: you might want to create a new integer column with YYYYMM format. e.g. `2009-12-01 07:45:00 -> 200912` which allows easy GROUP BY.\n",
    "\n",
    "**Sample Plot:**\n",
    "\n",
    "![](https://i.imgur.com/tmLsPDf.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_year_month_df = retail_df\n",
    "invoice_year_month_df[\"yyyymm\"] = (retail_df[\"InvoiceDate\"].dt.year.astype(str) + retail_df[\"InvoiceDate\"].dt.month.astype(int).map(\"{:02}\".format).astype(str)).astype(int)\n",
    "monthly_cancelled_orders_df = invoice_year_month_df.loc[(invoice_year_month_df[\"Quantity\"] < 0) | (invoice_year_month_df[\"Price\"] < 0)].groupby(\"yyyymm\").size()\n",
    "monthly_placed_orders_df = invoice_year_month_df.groupby(\"yyyymm\").size() - 2 * monthly_cancelled_orders_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([monthly_placed_orders_df, monthly_cancelled_orders_df], axis=1).reset_index()\n",
    "df.columns = [\"yyyymm\", \"Placement\", \"Cancellation\"]\n",
    "df.plot(x=\"yyyymm\", y=[\"Placement\", \"Cancellation\"], kind=\"bar\", figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "\n",
    "- Calculate the monthly sales data\n",
    "- Plot a chart to show monthly sales (e.g. x-asix=year_month, y-axis=sales_amount)\n",
    "\n",
    "![](https://i.imgur.com/k1KOqKO.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales Growth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "- Calculate monthly sales percentage growth data\n",
    "- Plot a chart to show the growth percentage\n",
    "\n",
    "![](https://i.imgur.com/J3btp8j.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Active Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "- Compute # of active users (e.g. unique `CusotomerID`) for each month\n",
    "- Plot a bar chart\n",
    "\n",
    "![](https://i.imgur.com/eFYp8VF.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New and Existing Users\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "\n",
    "- Plot a diagram to show new and exiting user for each month.\n",
    "- A user is identified as a new user when he/she makes the first purchase\n",
    "- A user is identified as an existing user when he/she made purchases in the past\n",
    "- hints:\n",
    "  - find out the first purchase year-month for each user and then join this data with the transactional data to help you identified new/exiting users\n",
    "\n",
    "![](https://i.imgur.com/nWjnrpr.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding RFM\n",
    "\n",
    "RFM is a method used for analyzing customer value. It is commonly used in database marketing and direct marketing and has received particular attention in the retail and professional services industries. ([wikipedia](https://en.wikipedia.org/wiki/RFM_(market_research)))\n",
    "\n",
    "Optional Reading: [Making Your Database Pay Off Using Recency Frequency and Monetary Analysis](http://www.dbmarketing.com/2010/03/making-your-database-pay-off-using-recency-frequency-and-monetary-analysis/)\n",
    "\n",
    "\n",
    "RFM stands for three dimensions:\n",
    "\n",
    "- Recency – How recently did the customer purchase?\n",
    "\n",
    "- Frequency – How often do they purchase?\n",
    "\n",
    "- Monetary Value – How much do they spend?\n",
    "\n",
    "Note: To simplify the problem, let's keep all placed and canceled orders.\n",
    "\n",
    "\n",
    "**Sample RFM table**\n",
    "\n",
    "![](https://i.imgur.com/sXFIg6u.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFM Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Please remove this insturction cell after you are done with coding**\n",
    "RFM segmentation categorizes your customers into different segments, according to their interactions with your website, which will allow you to subsequently approach these groups in the most effective way. In this article, we will show you how to make an RFM segmentation based on an RFM score combining all three RFM parameters together and allowing you to divide your customers into 11 different segments. \n",
    "\n",
    "- [RFM Segmentation business cases](https://docs.exponea.com/docs/rfm-segmentation-business-use)\n",
    "\n",
    "- [RFM Segmentation Guide](https://docs.exponea.com/docs/rfm-segmentation-business-use)\n",
    "\n",
    "As you can see, computing RFM segmentation requires extensive domain knowledge in marketing which is out of the scope in this project. In practice, you will work with BA/DA to figure out how to compute RFM segments. To simplify this project, a [sample RFM segmentation Notebook](https://github.com/jarviscanada/jarvis_data_eng_demo/blob/feature/data/python_data_wrangling/ipynb/customer-segmentation-with-rfm-score.ipynb) is provided. You are responsible to understand everything from that Notebook and then integrate it into yours. \n",
    "\n",
    "- Download the [sample notebook](https://github.com/jarviscanada/jarvis_data_eng_demo/blob/feature/data/python_data_wrangling/ipynb/customer-segmentation-with-rfm-score.ipynb) and import to your Jupyter Notebook or VSCode\n",
    "- Run the notebook and understand all cells\n",
    "- Read the remark section at the end of the notebook. You will need this information when writing the README file\n",
    "- Integrate the RFM segmentation calculation into your notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0f79b083b93e31849541153e18d7629d66d82d2ff6485732e43f16e6ae79e9377",
   "display_name": "Python 3.9.5  ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "f79b083b93e31849541153e18d7629d66d82d2ff6485732e43f16e6ae79e9377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}